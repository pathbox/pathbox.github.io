---
layout: post
title: 最近工作总结(42)
date:  2020-10-01 18:15:06
categories: Work
image: /assets/images/post.jpg

---

 

### Elasticsearch+HBase的存储方案

Elasticsearch中存储需要的索引字段，完整的数据存储在HBase。HBase适合海量数据的在线存储，不适合复杂的搜索，但是简单的根据id或者范围查询性能上没有问题。从Elasticsearch中进行复杂搜索得到对应的doc id，然后再到HBase中查询完整的数据返回给前端。这样，Elasticsearch中只存储必要的索引字段，能够更节省内存，使得Elasticsearch能更高效的使用内存(filesystem cache)，从而获得更高的查询性能

### scroll 的分页方式

类似于微博中，下拉刷微博，刷出来一页一页的分页数据。性能会比上面说的那种分页性能要高很多很 多，基本上都是毫秒级的。缺点是：不能随意跳到任何一页的场景

### Redis持久化 AOF和RDB相结合

Redis 支持同时开启开启两种持久化方式，我们可以综合使用 AOF 和 RDB 两种持久化机 制，用 AOF 来保证数据不丢失，作为数据恢复的第一选择; 用 RDB 来做不同程度的冷备， 在 AOF 文件都丢失或损坏不可用的时候，还可以使用 RDB 来进行快速的数据恢复

### 限流降级的作用

防止系统服务或数据库完全被打挂而僵死，无法处理任何新请求。数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。 只要数据库不死，就是说，对用户来说，2/5 的请求都是可以被处理的。 只要有 2/5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷 不出来页面，但是多点几次，就可以刷出来了

### 用MQ缓解数据库并发写操作

可能你还是会出现高并发写的场景，比如说一个业务操作里要频繁搞数据 库几十次，增删改增删改，那高并发绝对搞挂你的系统，你要是用 redis 来承载写那肯 定不行，人家是缓存，数据随时就被 LRU 了，数据格式还无比简单，没有事务支持。所以该用 mysql 还得用 mysql 啊。用 MQ 吧，大量的写请求灌入 MQ 里，排队慢慢玩儿， ，控制在 mysql 承载范围之内。所以你得考虑考虑你的项目里，那些承 载复杂写业务逻辑的场景里，如何用 MQ 来异步写，提升并发性。MQ 单机抗几万并发也是 ok 的

### 从大量数据中查找重复数据(字符串or整数)

1. hash取余分治到小一些的文件
2. 使用hashmap查重过滤
3. 对于大量整数查重，使用bitmap方式，或者布隆过滤器



### ProtoBuf的优点

其实 PB 之所以性能如此好，主要得益于两个：它使用 proto 编译器，自动进行序列化 和反序列化，速度非常快，应该比 XML 和 JSON 快上了 20~100 倍； 它的数据压缩 效果好，就是说它序列化后的数据量体积小。因为体积小，传输起来带宽和速度上会有优化。



### 对订单付款幂等性的设计

一个订单可以分为：下单和付款两个部分。对于每个请求必须有一个唯一的标识，举个栗子：订单支付请求，肯定得包含订单 id，一 个订单 id 最多支付一次，对吧。 每次处理完请求之后，必须有一个记录标识这个请求处理过了。常见的方案是在 mysql 中 记录个状态啥的，比如支付之前记录一条这个订单的支付流水。 每次接收请求需要进行判断，判断之前是否处理过。比如说，如果有一个订单已经支付 了，就已经有了一条支付流水，那么如果重复发送这个请求，则此时先插入支付流水， orderId 已经存在了，唯一键约束生效，报错插入不进去的。然后你就不用再扣款了。

实际运作过程中，你要结合自己的业务来，比如说利用 Redis，用 orderId 作为唯一键。只有成 功插入这个支付流水，才可以执行实际的支付扣款。

要求是支付一个订单，必须插入一条支付流水，order_id 建一个唯一键 unique key 。你在支 付一个订单之前，先插入一条支付流水，order_id 就已经进去了。你就可以写一个标识到 Redis 里面去， set order_id payed ，下一次重复请求过来了，先查 Redis 的 order_id 对应的 value，如果是 payed 就说明已经支付过了，你就别重复支付了