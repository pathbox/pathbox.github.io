---
layout: post
title: 最近工作总结(48)
date:  2021-04-08 20:00:00
categories: Work
image: /assets/images/post.jpg


---

​    

### 接口耗时暴增原因排查

起因: 调用方部门反馈某个内部接口耗时突然增加了，导致原本超时时间设置太小，而接口超时失败。

快速处理：调用方将接口超时时间增大到合适值

排查：通过监控查看该接口一周的调用情况，发现确实从2天前开始，接口耗时从100ms左右飙升到了3-4s。但是，接口调用请求量并没有暴涨，和之前差不多

- 先从代码入手，查看2天前的那个时间点后，代码上是否有变更导致。 结果：代码没有问题
- 构造一个测试数据，发起测试请求，得到的请求耗时正常100ms内。从日志中过找出一个耗时长的请求，重新测试，请求耗时3s
- 将接口中涉及到的所有SQL操作列出，搜索数据库慢日志，看是否有对应慢日志。结果：没有对应慢日志
- 根据耗时3s请求的参数，手动在数据库上执行SQL，SQL耗时正常，均在20ms完成。结果：SQL，数据库性能应该正常
- 接口业务中是否有调第三方API。结果：没有
- 接口业务中发现有用tcp方式非http方式调用第三方的服务。通过对比测试调用和不调用该tcp第三方服务，是该服务有问题。但由于这块老代码中，没有超时或者报错提示，导致日志中没有报错信息，问题被隐藏

解决方式：

- 通知该tcp服务负责人员
- 将该调用加上相应超时和报错信息日志
- 异步方式调用该tcp服务

还有哪些方向可以查：

- 局域网网络是否有问题
- DNS解析是否耗时过长
- 对应前置内部网关是否有问题
- 调用方部门的服务是否部署到了别的地域导致不再同一个局域网内



### go context cancel不执行会怎样

If you fail to cancel the context, the [goroutine that WithCancel or WithTimeout created](https://golang.org/src/context/context.go?s=9162:9288) will be retained in memory indefinitely (until the program shuts down), causing a memory leak. If you do this a lot, your memory will balloon significantly. It's best practice to use a `defer cancel()` immediately after calling `WithCancel()` or `WithTimeout()`

很有可能会导致内存泄漏

在goroutine中往channel写入数据，很可能由于读取channel的逻辑错误而没法执行到读取channel而导致写入channel的goroutine一直阻塞,造成goroutine泄漏，GC也不会将其回收。该阻塞的goroutine实际上被认为还在使用

### go 内存逃逸示例

`golang程序变量`会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在`栈上`分配。否则就说它 `逃逸` 了，必须在`堆上分配`。

能引起变量逃逸到堆上的**典型情况**：

- **在方法内把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。
- **发送指针或带有指针的值到 channel 中。** 在编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。
- **在一个切片上存储指针或带指针的值。** 一个典型的例子就是 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。
- **slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。** slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。
- **在 interface 类型上调用方法。** 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配

```go
package main
import "fmt"
type A struct {
 s string
}
// 这是上面提到的 "在方法内把局部变量指针返回" 的情况
func foo(s string) *A {
 a := new(A) 
 a.s = s
 return a //返回局部变量a,在C语言中妥妥野指针，但在go则ok，但a会逃逸到堆
}
func main() {
 a := foo("hello")
 b := a.s + " world"
 c := b + "!"
 fmt.Println(c)
}

// go build -gcflags=-m main.go
```



### 如何处理大量的写请求

一些具体的场景

- 如果相应的数据能够完全放入缓存中，可以考虑利用redis集群当数据库使用
- 如果写请求不需要立刻知道结果，业务逻辑上可以有一定的延迟。将写请求消息发到消息队列中(RocketMQ)，通过消息队列消费者写入到数据库。消息队列有重试机制，能尽可能的提高成功率
- 对写请求即时性比较高，考虑先将写操作在缓存中进行，然后再通过消息队列持久化到数据库

写请求是量大，并非并发多

- 是否能够将写操作合为批量处理
- 数据库可以考虑使用分布式数据库
- 消息队列异步处理



### 自旋锁和互斥锁

**自旋锁(spin lock)与互斥量(mutex)的比较** 自旋锁是一种非阻塞锁，也就是说，如果某线程需要获取自旋锁，但该锁已经被其他线程占用时，该线程不会被挂起，而是在不断的消耗CPU的时间，不停的试图获取自旋锁。 互斥量是阻塞锁，当某线程无法获取互斥量时，该线程会被直接挂起，该线程不再消耗CPU时间，当其他线程释放互斥量后，[**操作系统**](http://lib.csdn.net/base/operatingsystem)会激活那个被挂起的线程，让其投入运行。

**两种锁适用于不同场景：** 如果是多核处理器，如果预计线程等待锁的时间很短，短到比线程两次上下文切换时间要少的情况下，使用自旋锁是划算的。 如果是多核处理器，如果预计线程等待锁的时间较长，至少比两次线程上下文切换的时间要长，建议使用互斥量。 如果是单核处理器，一般建议不要使用自旋锁。因为，在同一时间只有一个线程是处在运行状态，那如果运行线程发现无法获取锁，只能等待解锁，但因为自身不挂起，所以那个获取到锁的线程没有办法进入运行状态，只能等到运行线程把操作系统分给它的时间片用完，才能有机会被调度。这种情况下使用自旋锁的代价很高。 如果加锁的代码经常被调用，但竞争情况很少发生时，应该优先考虑使用自旋锁，自旋锁的开销比较小，互斥量的开销较大

 

###Trie树对Hash表

> Trie树，即字典树，又称单词查找树或键树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计和排序大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：最大限度地减少无谓的字符串比较，查询效率比哈希表高。
>
> Trie的核心思想是空间换时间。利用字符串的公共前缀来降低查询时间的开销以达到提高效率的目的
>
> - 根节点不包含字符，除根节点外每一个节点都只包含一个字符
> - 从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串
> - 每个节点的所有子节点包含的字符都不相同

 

### 使用redis为kv存储实现索引

kv中的数据是这样的： id => {status}_xxx_{created_at} 

定义status有10中状态值：1-10

希望实现的索引，能够根据status搜索，并且可以按照created_at排序(倒序)输出。还能实现分页功能

1. 实现一个B+树（这个方法比较复杂）
2. 使用redis的zset有序集合

使用redis的zset有序集合可以实现一个类似"倒排索引"的索引结构

```
ZADD {status} {created_at} id

ZREVRANGE {status} 0 10 withscores
```

这样就根据created_at值倒序输出10个值

zset可以方便的实现根据score排序和分页

- 页面总数为：`ZCOUNT`命令
- 当前页内容：`ZRANGE`命令
- 若以倒序排列：`ZREVRANGE`命令

zset也有移除操作，可以方便移除索引值

根据status进行搜索输出可否实现呢？

比如：需要得到status > 3 的结果。

1. 遍历 4-10的key，把所有结果找出来，再合并，再根据created_at排序

2. 使用zset的zunionstore：对给定的有序集合执行类似于集合的并集运算。

但是，使用zunionstore会有一个问题，当member 这里是status相同的话，会将score进行合并计算，这样就改变了原有的created_at值。因为zunionstore本质是进行交集合并操作。所以zunionstore的方法适合一个id只有一个status值的情况，这样合并的时候，status是不会有冲突重复的，合并后得到新的zset的created_at值是保留原始值，不会是合并值而更改。然后得到合并后新的zset可以进行分页，对created_at排序输出。

3. 如果一个id可以有多个status呢？比如分页大小是10，需要遍历4-10的key，每个key根据created_at排序得到10个值，将这10个值放到一个数组中，再排序，再最后输出10个值。这步的操作和redis的命令几乎无关了，实际实现的效率可能就会差一些

https://segmentfault.com/a/1190000009821423

###在秒杀系统中redis存储库存的作用

redis中记录的库存主要用于即时判断库存是否充足，作用是过滤大部分秒杀请求，只接收库存数量的请求放入请求队列。并不需要与mysql中的库存保持强一致性。

所以本方案不需要保持两者数据的一致性。

### 异地多活，多主互相同步的基本原则

- 避免自增id的冲突

- 在某一时刻或时间段，通过一定的路由规则，保证某个用户的写操作只会在一个地域的数据库中操作，避免并发写不同主库的冲突问题

- 不需要异地多活的业务不进行异地多活，首先保证核心业务

- **避免冲突：**首先我们通过全局定义的规则避免数据冲突，仔细设计的数据规则，让每笔数据都有自己的归属机房，两个机房同时修改一笔数据的情况很少出现。两个机房产生的数据在 ID 上是错开的，各种和业务相关的ID 也通过设计避免了重复，这样数据复制到一起后，不会发生冲突。对于有唯一键索引的数据，我们也进行了改造，加上了用于区别机房的数据字段

   

### 火焰图怎么看

主要就是看那些比较宽大的火苗，特别留意那些类似平顶山的火苗

### redis主从复制

##### master主从模式

**全量同步**
Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： 

- 从服务器连接主服务器，发送SYNC命令； 
- 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； 
- 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令； 
-  从服务器收到快照文件后丢弃所有旧数据，载入收到的快照； 
-  主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令； 
-  从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令

**增量同步**

Redis增量复制是指Slave初始化后开始正常工作时主服务器发生的写操作同步到从服务器的过程。 
增量复制的过程主要是主服务器每执行一个写命令就会向从服务器发送相同的写命令，从服务器接收并执行收到的写命令

https://www.cnblogs.com/daofaziran/p/10978628.html

> Redis的RDB持久化实现是folk一个子进程，然后让子进程将内存镜像dump到RDB文件中。理论上来说是需要跟父进程一样的内存空间，也就是27.55G，但是由于[Linux](http://lib.csdn.net/base/linux)很早就支持的copy-on-write技术，所以实际上并不需要这么多的物理内存的，这个可以从log中分析出来。我们这个Redis最多只有150M左右的COW内存。
>
> 每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。在数据集比较庞大时， fork()可能会非常耗时，造成服务器在某某毫秒内停止处理客户端；如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒

##### cluster主从模式

一个master可以有多个slave。在同一个节点上的所有slot的所有的写操作都会被从master节点异步复制到所有的slave节点

### bitmap的内存占用

2^32次方是4294967296(42亿+)，如果是一个bitmap就是4294967296位，大约512M。1亿个bit，是95.3M

### 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url

    方案1：可以估计每个文件安的大小为5G×64=320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。
    
    遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件（记为a0,a1,...,a999）中。这样每个小文件的大约为300M。
    
    遍历文件b，采取和a相同的方式将url分别存储到1000小文件（记为b0,b1,...,b999）。这样处理后，所有可能相同的url都在对应的小文件（a0vsb0,a1vsb1,...,a999vsb999）中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。
    
    求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。
    
    方案2：如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url（注意会有一定的错误率）

###服务降级

从概念上来说，所谓的服务降级，是当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面进行策略性的屏蔽或降低服务质量，以此释放服务器资源以保证核心任务的正常运行。

从使用场景来说，当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，我们可以将一些**不重要**或**不紧急**的服务或任务进行服务的**延迟使用**或**暂停使用**。

服务降级的方式或策略其实有多种，除了限流和熔断，常用的还有以下这些：

- **关闭次要服务**：在服务压力过大时，关闭非核心功能的服务，避免核心功能被拖垮。比如，淘宝双11活动当天，订单量激增，为了保证核心的交易业务的高可用，就会暂时关闭非核心的退货服务。

- **丢弃部分请求**：对于一些老请求——即从接收到处理的时间已经超过了一定时间（比如1s）的请求，可以直接丢弃。还可以根据请求的优先级，有选择性地丢弃那些优先级低的请求。或者随机丢弃一定比例的请求。

- **读降级**：对于读一致性要求不高的场景，在服务和数据库压力过大时，可以不读数据库，降级为只读缓存数据，以这种方式来减小数据库压力，提高服务的吞吐量。对于列表、分页功能，原本返回20个记录，给予返回5个记录。并且关闭跳过大量分页的查询

- **写降级**：在服务压力过大时，可以将同步写转为异步写，来减小服务压力并提高吞吐量。既然把同步改成了异步也就意味着降低了数据一致性，保证数据最终一致即可。

- **屏蔽写入**：很多高并发场景下，查询请求都会走缓存，这时数据库的压力主要是写入压力。所以对于某些不重要的服务，在服务和数据库压力过大时，可以关闭写入功能，只保留查询功能，这样可以明显减小数据库压力。

- **数据冗余**：服务调用者可以冗余它所依赖服务的数据。当依赖的服务故障时，服务调用者可以直接使用冗余数据。

  

以上列出来的只是部分降级方式而已，并没有涵盖所有情况。实际上，关于服务降级的方式和策略，并没有什么定式，也没有标准可言。不过，所有的降级方案都要以满足业务需求为前提，都是为了提高系统的可用性，保证核心功能正常运行。

从分类上来说，可以把服务降级分为**手动降级**和**自动降级**两大类。手动降级应用较多，主要通过开关的方式开启或关闭降级。自动降级，比如限流和熔断就属于这一类。手动降级大多也可以做成自动的方式，可根据各种系统指标配置阈值，当相应指标达到阈值时则自动开启降级。不过，在很多场景下，由于业务比较复杂，指标太多，自动降级实现起来难度比较大，而且也容易出错。所以在考虑做自动降级之前一定要充分做好评估，相应的自动降级方案也要考虑周全。

### 为什么存在大端模式小端模式

计算机系统中内存是以字节为单位进行编址的，每个地址单元都唯一的对应着1个字节（8 bit）。这可以应对char类型数据的存储要求，因为char类型长度刚好是1个字节，但是有些类型的长度是超过1个字节的（字符串虽然是多字节的，但它本质是由一个个char类型组成的类似数组的结构而已），比如C/C++中，short类型一般是2个字节，int类型一般4个字节等。因此这里就存在着一个如何安排多个字节数据中各字节存放顺序的问题。正是因为不同的安排顺序导致了**大端存储模式**和**小端存储模式**的存在。

## **小端模式**

小端模式：是指数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中。
简单的说就是**低地址存低位，高地址存高位**

为了方便说明，使用16进制表示这两个数，即0x12345678和0x11223344。小端模式采用以下方式存储这个两个数字：



![img](https://pic4.zhimg.com/80/v2-81dd19d1927d8845a11196364d36098f_1440w.jpg)



## **大端模式**

大端模式：是指数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中。
简单的上，就是**低地址存高位，高地址存低位**（跟人读写数值的顺序一样）
为了方便说明，使用16进制表示这两个数，即0x12345678和0x11223344。大端模式采用以下方式存储这个两个数字：



![img](https://pic1.zhimg.com/80/v2-68d3e942010ffc918c194898312f8448_1440w.jpg)



## **为什么没有统一成一个标准**

一言以蔽之，这两种模式各有各的优点。

**小端模式优点**：

1. 内存的低地址处存放低字节，所以在强制转换数据时不需要调整字节的内容（注解：比如把int的4字节强制转换成short的2字节时，就直接把int数据存储的前两个字节给short就行，因为其前两个字节刚好就是最低的两个字节，符合转换逻辑）；
2. CPU做数值运算时从内存中依顺序依次从低位到高位取数据进行运算，直到最后刷新最高位的符号位，这样的运算方式会更高效

**大端模式优点**：符号位在所表示的数据的内存的第一个字节中，便于快速判断数据的正负和大小

其各自的优点就是对方的缺点，正因为两者彼此不分伯仲，再加上一些硬件厂商的坚持，因此在多字节存储顺序上始终没有一个统一的标准

## **网络字节序**

不同的计算机使用的字节序可能不同，即有可能有的使用大端模式有的使用小端模式。那使用不同字节序模式的计算机如何进行通信呢？ （目前个人PC大部分都是X86的小端模式）
TCP/IP协议隆重出场，RFC1700规定使用“大端”字节序为网络字节序，其他不使用大端的计算机要注意了，发送数据的时候必须要将自己的主机字节序转换为网络字节序（即“大端”字节序），接收到的数据再转换为自己的主机字节序。这样就与CPU、操作系统无关了，实现了网络通信的标准化。

为了程序的兼容，你会看到，程序员们每次发送和接收数据都要进行转换，这样做的目的是保证代码在任何计算机上执行时都能达到预期的效果。

这么常用的操作，BSD Socket提供了封装好的转换接口，方便程序员使用。
包括从主机字节序到网络字节序的转换函数：htons、htonl；从网络字节序到主机字节序的转换函数：ntohs、ntohl

### 业务上的防重操作的必要性

如果你的接口，消息消费不是幂等的，一定要在业务上进行去重，比如有唯一标识，能根据唯一标识进行去重复识别。

不能单纯依靠系统或消息队列的去重能力