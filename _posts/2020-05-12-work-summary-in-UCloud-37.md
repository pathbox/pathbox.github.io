---
layout: post
title: 最近工作总结(37)
date:  2020-05-12 19:45:06
categories: Work
image: /assets/images/post.jpg
---

### 分布式ID生成的几种方案选择
https://www.cnblogs.com/cider/p/11776088.html
https://tech.meituan.com/2017/04/21/mt-leaf.html
snowflake 会遇到时间回拨的问题，一种解决思路：https://juejin.im/post/5a7f9176f265da4e721c73a8

对时间上有强依赖，则需要每隔几秒(3s)上报时间给ZooKeeper或etcd，在启动或重启服务的时候对进行集群节点的时间对比，超过阈值，则对应节点启动失败。如果该节点启动成功，可能当前节点会出现由于时间回拨过而导致生成一些列冲突的id。要保证时间是一直更大的，不能回拨

### 关于高可用服务的简单几点
- 服务无状态
- 幂等性
- 服务超时设置避免阻塞
- 异步-消息队列
- 高并发、高可用: 网关、限流、降级、缓存、容灾
- 数据: 备份、一致性(最终一致性)
- 集群，服务发现和服务注册

### Redis::CommandError: CROSSSLOT Keys in request don’t hash to the same slot
mset（Multi-key）del keys... 等命令，报错：
Redis::CommandError: CROSSSLOT Keys in request don’t hash to the same slot
原因： Redis cluster对多key操作有限，要求命令中所有的key都属于一个slot，才可以被执行。客户端可以对multi-key命令进行拆分，再发给redis。
另外一个局限是，在slot迁移过程中，multi-key命令特别容易报错(CROSSSLOT Keys in request don’t hash to the same slot)。建议不用multi-key命令。

解决： 在key名中增加{XXXX}，这样redis将仅使用XXXX来计算slot的位置

### 缓存问题概念补充
缓存穿透
缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。这种查询不存在数据的现象我们称为缓存穿透

解决方案
有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。
另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

缓存雪崩
缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。

解决方案
缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。
使用 Hystrix进行限流 & 降级 ，比如一秒来了5000个请求，我们可以设置假设只能有一秒 2000个请求能通过这个组件，那么其他剩余的 3000 请求就会走限流逻辑。然后去调用我们自己开发的降级组件（降级），比如设置的一些默认值呀之类的。以此来保护最后的 MySQL 不会被大量的请求给打死。

缓存击穿
对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题: 缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。

缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮

上面的现象是多个线程同时去查询数据库的这条数据，那么我们可以在第一个查询数据的请求上使用一个 互斥锁来锁住它。
其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存.查数据库之前，看锁有没有被拿走，说明前面有请求已经在查数据库更新缓存了，当锁释放了，直接尝试去读缓存。如果没拿到数据，而且也拿到锁了，就去查数据库，然后更新缓存

### Redis为什么是单线程、高并发
官方回答: 因为Redis是基于内存的操作，CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存的大小或者网络带宽。既然单线程容易实现，而且CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了

- 不需要各种锁的性能消耗，没有死锁问题
- 保证了每个操作的原子性，省去了很多上下文切换线程的时间
- 单机多线程的上限也往往不能满足需要了，需要进一步摸索的是多服务器集群化的方案，这些方案中多线程的技术照样是用不上的.所以单线程、多进程的集群不失为一个时髦的解决方案(部署多个redis实例)
-  redis 采用非阻塞IO多路复用技术（尽量减少网络IO的时间消耗）来实现网络并发操作，epoll

### Golang的逃逸分析简记
逃逸分析这种“骚操作”把变量合理地分配到它该去的地方，“找准自己的位置”。即使你是用new申请到的内存，如果我发现你竟然在退出函数后没有用了，那么就把你丢到栈上，毕竟栈上的内存分配比堆上快很多；反之，即使你表面上只是一个普通的变量，但是经过逃逸分析后发现在退出函数之后还有其他地方在引用，那我就把你分配到堆上。真正地做到“按需分配”，提前实现共产主义！

如果变量都分配到堆上，堆不像栈可以自动清理。它会引起Go频繁地进行垃圾回收，而垃圾回收会占用比较大的系统开销（占用CPU容量的25%）
堆和栈相比，堆适合不可预知大小的内存分配。但是为此付出的代价是分配速度较慢，而且会形成内存碎片。栈内存分配则会非常快。栈分配内存只需要两个CPU指令：“PUSH”和“RELEASE”，分配和释放；而堆分配内存首先需要去找到一块大小合适的内存块，之后要通过垃圾回收才能释放。

通过逃逸分析，可以尽量把那些不需要分配到堆上的变量直接分配到栈上，堆上的变量少了，会减轻分配堆内存的开销，同时也会减少gc的压力，提高程序的运行速度

编译器会根据变量是否被外部引用来决定是否逃逸：

如果函数外部没有引用，则优先放到栈中；

如果函数外部存在引用，则必定放到堆中；

逃逸的常见情况

发送指针的指针或值包含了指针到 channel 中，由于在编译阶段无法确定其作用域与传递的路径，所以一般都会逃逸到堆上分配。

slices 中的值是指针的指针或包含指针字段。一个例子是类似`[]*string` 的类型。这总是导致 slice 的逃逸。即使切片的底层存储数组仍可能位于堆栈上，数据的引用也会转移到堆中。

slice 由于 append 操作超出其容量，因此会导致 slice 重新分配。这种情况下，由于在编译时 slice 的初始大小的已知情况下，将会在栈上分配。如果 slice 的底层存储必须基于仅在运行时数据进行扩展，则它将分配在堆上。

调用接口类型的方法。接口类型的方法调用是动态调度 - 实际使用的具体实现只能在运行时确定。考虑一个接口类型为 io.Reader 的变量 r。对 r.Read(b) 的调用将导致 r 的值和字节片b的后续转义并因此分配到堆上。 参考 http://npat-efault.github.io/programming/2016/10/10/escape-analysis-and-interfaces.html

尽管能够符合分配到栈的场景，但是其大小不能够在在编译时候确定的情况，也会分配到堆上

```go
package main

func main() {
	a := f1()
	*a++
}

//go:noinline
func f1() *int {
	i := 1
	return &i
}
```
```
go build -gcflags '-m' escape.go
 command-line-arguments
./escape.go:3:6: can inline main
./escape.go:11:9: &i escapes to heap
./escape.go:10:2: moved to heap: i

go tool compile -S escape.go | grep escape.go:10
	0x001d 00029 (escape.go:10)	PCDATA	$2, $1
	0x001d 00029 (escape.go:10)	PCDATA	$0, $0
	0x001d 00029 (escape.go:10)	LEAQ	type.int(SB), AX
	0x0024 00036 (escape.go:10)	PCDATA	$2, $0
	0x0024 00036 (escape.go:10)	MOVQ	AX, (SP)
	0x0028 00040 (escape.go:10)	CALL	runtime.newobject(SB)
	0x002d 00045 (escape.go:10)	PCDATA	$2, $1
	0x002d 00045 (escape.go:10)	MOVQ	8(SP), AX
	0x0032 00050 (escape.go:10)	MOVQ	$1, (AX)

这里的 00040 有调用 runtime.newobject(SB) 这个方法
```

堆heap数据量太多会导致GC压力增大

### UUID 通用唯一识别码
Universally Unique Identifier
https://zh.wikipedia.org/wiki/%E9%80%9A%E7%94%A8%E5%94%AF%E4%B8%80%E8%AF%86%E5%88%AB%E7%A0%81

- 128bit
- UUID的标准型式包含32个16进制数字，以连字号分为五段，形式为 8-4-4-4-12 的32个字符。示例：550e8400-e29b-41d4-a716-446655440000

- 版本1 - UUID 是根据时间和节点 ID（通常是MAC地址）生成；
- 版本2 - UUID是根据标识符（通常是组或用户ID）、时间和节点ID生成；
- 版本3、版本5 - 确定性UUID 通过散列（hashing）名字空间（namespace）标识符和名称生成；
- 版本4 - UUID 使用随机性或伪随机性生成。

### 证书文件后缀
证书(Certificate)
- X.509：一种通用的整数格式，包含证书持有人的公钥，加密算法等信息
- PKCS1-PKCS12：公钥加密(非对称加密)的一种标准，一般存储为*pN, `*.p12`是包含证书和密钥的封装格式
- `*.der`：证书的二进制存储格式(不常用)
- `*.pem`：证书或密钥的Base64文本存储格式，可以单独存放证书或密钥，也可以同时存放证书或密钥
- `*.key`：单独存放的pem格式的密钥，一般保存为*.key
- `*.cer *.crt`：两个指的都是证书，Linux下教crt，Windows下教cer；存储格式可以是pem，也可以是der
- `*.csr`：证书签名请求，包含证书持有人的信息，如：国家，邮件，域名等信息


### 邮箱、域名不区分大小写
在数据库设计的时候，最好对邮箱或域名这种信息都进行小写格式化，因为虽然数据库方面可以设置不区分大小写，但是在redis中key是区分的，所以进行统一的格式，可以避免后续的一些问题

### 开放寻址法
当我们向当前哈希表写入新的数据时发生了冲突，就会将键值对写入到下一个不为空的位置。当 Key3 与已经存入哈希表中的两个键值对 Key1 和 Key2 发生冲突时，Key3 会被写入 Key2 后面的空闲内存中；当我们再去读取 Key3 对应的值时就会先对键进行哈希并取模，这会帮助我们找到 Key1，因为 Key1 与我们期望的键 Key3 不匹配，所以会继续查找后面的元素，直到内存为空或者找到目标元素
当需要查找某个键对应的值时，就会从索引的位置开始对数组进行线性探测，找到目标键值对或者空内存就意味着这一次查询操作的结束。

开放寻址法中对性能影响最大的就是装载因子，它是数组中元素的数量与数组大小的比值，随着装载因子的增加，线性探测的平均用时就会逐渐增加，这会同时影响哈希表的读写性能，当装载率超过 70% 之后，哈希表的性能就会急剧下降，而一旦装载率达到 100%，整个哈希表就会完全失效，这时查找任意元素都需要遍历数组中全部的元素，所以在实现哈希表时一定要时刻关注装载因子的变化
哈希函数返回的哈希会帮助我们选择一个桶，和开放地址法一样，选择桶的方式就是直接对哈希返回的结果取模

在一个性能比较好的哈希表中，每一个桶中都应该有 0~1 个元素，有时会有 2~3 个，很少会超过这个数量，计算哈希、定位桶和遍历链表三个过程是哈希表读写操作的主要开销，使用拉链法实现的哈希也有装载因子这一概念：

装载因子 := 元素数量 / 桶数量
与开放地址法一样，拉链法的装载因子越大，哈希的读写性能就越差，在一般情况下使用拉链法的哈希表装载因子都不会超过 1，当哈希表的装载因子较大时就会触发哈希的扩容，创建更多的桶来存储哈希中的元素，保证性能不会出现严重的下降。如果有 1000 个桶的哈希表存储了 10000 个键值对，它的性能是保存 1000 个键值对的 1/10，但是仍然比在链表中直接读写好 1000 倍

### UTF-8与Unicode
http://cenalulu.github.io/linux/character-encoding/

UTF-8是变长的字符编码:1-3个字节。

那么解释UTF-8和Unicode的关系就比较简单了。Unicode就是上文中提到的编码字符集，而UTF-8就是字符编码，即Unicode规则字库的一种实现形式

### Go 语言选择了传值的方式
传值：函数调用时会对参数进行拷贝，被调用方和调用方两者持有不相关的两份数据；
传引用：函数调用时会传递参数的指针，被调用方和调用方两者持有相同的数据，任意一方做出的修改都会影响另一方
Go 语言选择了传值的方式，无论是传递基本类型、结构体还是指针，都会对传递的参数进行拷贝
```go
type MyStruct struct {
	i int
}

func myFunction(a MyStruct, b *MyStruct) {
	a.i = 31
	b.i = 41
	fmt.Printf("in my_function - a=(%d, %p) b=(%v, %p)\n", a, &a, b, &b)
}

func main() {
	a := MyStruct{i: 30}
	b := &MyStruct{i: 40}
	fmt.Printf("before calling - a=(%d, %p) b=(%v, %p)\n", a, &a, b, &b)
	myFunction(a, b)
	fmt.Printf("after calling  - a=(%d, %p) b=(%v, %p)\n", a, &a, b, &b)
}

$ go run main.go
before calling - a=({30}, 0xc000018178) b=(&{40}, 0xc00000c028)
in my_function - a=({31}, 0xc000018198) b=(&{41}, 0xc00000c038)
after calling  - a=({30}, 0xc000018178) b=(&{41}, 0xc00000c028)
从运行的结果我们可以得出如下结论：

传递结构体时：会对结构体中的全部内容进行拷贝；
传递结构体指针时：会对结构体指针进行拷贝；
对结构体指针的修改是改变了指针指向的结构体，b.i 可以被理解成 (*b).i。对传递的指针进行了拷贝，但是可以修改指针指向的结构体
```
